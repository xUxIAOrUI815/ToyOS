// os/task.c
#include <stdint.h>

void printf(char *fmt, ...);
void* frame_alloc(); // mm.c
typedef uint64_t* pagetable_t; // paging.c
pagetable_t uvm_create();
void uvm_map(pagetable_t pagetable, uint64_t va, uint64_t pa, uint64_t size, int perm);
extern void __switch(uint64_t *current_cx_ptr, uint64_t *next_cx_ptr);

// --- å®å®šä¹‰ ---
#define PAGE_SIZE 4096
#define MAX_APP_NUM 4
// ç”¨æˆ·ç¨‹åºåœ¨è™šæ‹Ÿå†…å­˜ä¸­çš„å…¥å£åœ°å€ (è®© App ä»¥ä¸ºè‡ªå·±ä» 0 å¼€å§‹ï¼Œæˆ–è€… 0x1000)
#define USER_BASE_ADDR 0x10000 

// PTE æ ‡å¿—ä½
#define PTE_R (1L << 1)
#define PTE_W (1L << 2)
#define PTE_X (1L << 3)
#define PTE_U (1L << 4)

typedef struct {
    uint64_t ra;
    uint64_t sp;
    uint64_t s[12];
} TaskContext;

typedef struct {
    int is_running;
    TaskContext context;
    uint64_t user_stack[PAGE_SIZE / 8];   // æš‚æ—¶è¿˜æ˜¯æ”¾åœ¨å†…æ ¸é‡Œç®¡ç†
    uint64_t kernel_stack[PAGE_SIZE / 8];
    pagetable_t pagetable;                // ğŸ”´ æ¯ä¸ªä»»åŠ¡ç‹¬ç«‹çš„é¡µè¡¨
    uint64_t trap_cx_ppn;                 // Trapä¸Šä¸‹æ–‡æ‰€åœ¨çš„ç‰©ç†é¡µå·
} TaskControlBlock;

TaskControlBlock tasks[MAX_APP_NUM];
int app_num = 0;
TaskContext idle_cx;
int current_task_id = -1;

extern uint64_t _app_start;
extern uint64_t _app_end;
extern void __restore_to_user();
extern pagetable_t kernel_pagetable; // paging.c

// ç®€å•çš„ memcpy
void my_memcpy(void *dst, void *src, uint64_t len) {
    char *d = dst; char *s = src;
    while(len--) *d++ = *s++;
}

void task_init() {
    printf("[Kernel] Initializing tasks with Virtual Memory...\n");
    app_num = 3; 

    // App çš„å¤§å°
    uint64_t app_size = (uint64_t)&_app_end - (uint64_t)&_app_start;

    for (int i = 0; i < app_num; i++) {
        // 1. åˆ›å»ºç”¨æˆ·é¡µè¡¨
        // æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬å·ä¸ªæ‡’ï¼Œç›´æ¥å¤åˆ¶å†…æ ¸é¡µè¡¨ä½œä¸ºåŸºç¡€
        // è¿™æ ·ç”¨æˆ·æ€é™·å…¥å†…æ ¸æ—¶ï¼Œå†…æ ¸ä»£ç ä¾ç„¶å¯è§
        // åœ¨ä¸¥è‚ƒçš„ OS ä¸­ï¼Œåº”è¯¥åªæ˜ å°„ Trampolineï¼Œè¿™é‡Œä¸ºäº†æ•™å­¦ç®€åŒ–
        tasks[i].pagetable = (pagetable_t)frame_alloc();
        my_memcpy(tasks[i].pagetable, kernel_pagetable, PAGE_SIZE);

        // 2. åˆ†é…ç‰©ç†å†…å­˜æ¥å­˜æ”¾ User App ä»£ç 
        void *app_mem = frame_alloc(); // åˆ†é…ä¸€é¡µ (å‡è®¾ App < 4KB)
        my_memcpy(app_mem, &_app_start, app_size); // å¤åˆ¶ User App ä»£ç è¿›å»
        
        // 3. å»ºç«‹æ˜ å°„ï¼šè™šæ‹Ÿåœ°å€ 0x10000 -> åˆšåˆ†é…çš„ç‰©ç†åœ°å€
        // æƒé™ï¼šR | W | X | U (ç”¨æˆ·å¯è¯»å†™æ‰§è¡Œ)
        uvm_map(tasks[i].pagetable, USER_BASE_ADDR, (uint64_t)app_mem, PAGE_SIZE, 
                PTE_R | PTE_W | PTE_X | PTE_U);

        // 4. åˆå§‹åŒ– Trap ä¸Šä¸‹æ–‡
        // æ”¾åœ¨å†…æ ¸æ ˆé¡¶
        uint64_t kstack_top = (uint64_t)&tasks[i].kernel_stack[PAGE_SIZE/8];
        
        // ä¼ªé€  __switch è¿”å›åœ°å€
        tasks[i].context.ra = (uint64_t)__restore_to_user;
        tasks[i].context.sp = kstack_top;

        // å¡«å…… TrapContext
        typedef struct {
            uint64_t x[32];
            uint64_t sstatus;
            uint64_t sepc;
        } TrapContext;
        
        kstack_top -= sizeof(TrapContext);
        TrapContext *cx = (TrapContext *)kstack_top;
        tasks[i].context.sp = kstack_top;

        // ğŸ”´ User Status è®¾ç½®
        // SPP=0 (ç”¨æˆ·æ€), SPIE=1 (å¼€å¯ä¸­æ–­)
        // SUM=1 (å…è®¸å†…æ ¸è®¿é—®ç”¨æˆ·é¡µï¼Œå·æ‡’åšæ³•)
        cx->sstatus = (1L << 18); 
        
        // ğŸ”´ å…¥å£åœ°å€
        // App ä»¥ä¸ºè‡ªå·±ä» 0x10000 å¼€å§‹è·‘
        cx->sepc = USER_BASE_ADDR;
        
        // ç”¨æˆ·æ ˆ (æš‚æ—¶ä¸åšæ˜ å°„ï¼Œç›´æ¥ç”¨å†…æ ¸é‡Œçš„ç‰©ç†åœ°å€ï¼Œå› ä¸ºæˆ‘ä»¬å·æ‡’å¤åˆ¶äº†å†…æ ¸é¡µè¡¨)
        // åœ¨å®Œæ•´çš„ uCore ä¸­ï¼Œè¿™é‡Œåº”è¯¥åˆ†é…æ–°é¡µå¹¶æ˜ å°„åˆ°ç”¨æˆ·é«˜åœ°å€
        cx->x[2] = (uint64_t)&tasks[i].user_stack[PAGE_SIZE/8];

        tasks[i].is_running = 1;
        printf("[Kernel] Task %d created. PT=%x\n", i, tasks[i].pagetable);
    }
}

void schedule() {
    int next_id;
    if (current_task_id == -1) next_id = 0;
    else {
        next_id = (current_task_id + 1) % app_num;
        while (tasks[next_id].is_running == 0) {
            next_id = (next_id + 1) % app_num;
            if (next_id == current_task_id) {
                printf("[Kernel] All tasks finished!\n");
                while(1);
            }
        }
    }
    
    int prev_id = current_task_id;
    current_task_id = next_id;
    
    // ğŸ”´ åˆ‡æ¢é¡µè¡¨
    // è®¡ç®— satp å€¼ (Mode=8, PPN=tasks[next].pagetable)
    uint64_t next_satp = (8L << 60) | (((uint64_t)tasks[next_id].pagetable) >> 12);
    
    // å¿…é¡»åœ¨åˆ‡æ¢ä»»åŠ¡å‰/ååˆ‡æ¢ satp
    // è¿™é‡Œæˆ‘ä»¬ç®€å•ç²—æš´åœ°åœ¨ C è¯­è¨€é‡Œåˆ‡ (å®é™…ä¸Šåº”è¯¥åœ¨ switch.S é‡Œåˆ‡æ›´å®‰å…¨)
    asm volatile("csrw satp, %0" : : "r"(next_satp));
    asm volatile("sfence.vma"); // åˆ·æ–° TLB
    
    if (prev_id != -1) {
        // printf("[Kernel] Switch %d -> %d\n", prev_id, next_id);
        __switch((uint64_t *)&tasks[prev_id].context, (uint64_t *)&tasks[next_id].context);
    } else {
        printf("[Kernel] Idle -> Task %d\n", next_id);
        __switch((uint64_t *)&idle_cx, (uint64_t *)&tasks[next_id].context);
    }
}

void task_yield() { schedule(); }
void task_exit() { tasks[current_task_id].is_running = 0; schedule(); }